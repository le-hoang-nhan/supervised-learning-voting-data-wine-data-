{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LE HOANG NHAN\\PycharmProjects\\merging-dataframes -- Olympic data\n['.idea', '.ipynb_checkpoints', 'auto-mpg.csv', 'axis_limits.png', 'Bruce_McCandless_II_during_EVA_in_1984.jpg', 'finch_beaks_1975.csv', 'finch_beaks_2012.csv', 'gm_2008_region.csv', 'house-votes-84.csv', 'iris.csv', 'merging-dataframes-- Olympic data.ipynb', 'percent-bachelors-degrees-women-usa.csv', 'Plotting 2D arrays.ipynb', 'sine_mesh.png', \"statistic with Darwin's finches.ipynb\", 'stocks.csv', 'Summer Olympic medalists 1896 to 2008 - IOC COUNTRY CODES.csv', 'Summer Olympic medallists 1896 to 2008 - EDITIONS.csv', 'supervised-learning-with-scikit-learn.ipynb', 'venv', 'white-wine.csv', 'women degrees.ipynb', 'xlim_and_ylim.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "# Import scale\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline\n",
    "print(os.getcwd())\n",
    "print(os.listdir(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        party infants water budget physician salvador religious satellite aid  \\\n0  republican       0     1      0         1        1         1         0   0   \n1  republican       0     1      0         1        1         1         0   0   \n2    democrat       ?     1      1         ?        1         1         0   0   \n3    democrat       0     1      1         0        ?         1         0   0   \n4    democrat       1     1      1         0        1         1         0   0   \n\n  missile immigration synfuels education   superfund crime duty_free_exports  \\\n0       0           1        ?           1         1     1                 0   \n1       0           0        0           1         1     1                 0   \n2       0           0        1           0         1     1                 0   \n3       0           0        1           0         1     0                 0   \n4       0           0        1           ?         1     1                 1   \n\n  eaa_rsa  \n0       1  \n1       ?  \n2       0  \n3       1  \n4       1  \n"
     ]
    }
   ],
   "source": [
    "# Read in the data file: df\n",
    "df = pd.read_csv('house-votes-84.csv')\n",
    "df.replace(\"y\", 1,inplace=True)\n",
    "df.replace(\"n\", 0,inplace=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "party                  0\ninfants               12\nwater                 48\nbudget                11\nphysician             11\nsalvador              15\nreligious             11\nsatellite             14\naid                   15\nmissile               22\nimmigration            7\nsynfuels              21\neducation             31\nsuperfund             25\ncrime                 17\nduty_free_exports     28\neaa_rsa              104\ndtype: int64\nShape of Original DataFrame: (435, 17)\nShape of DataFrame After Dropping All Rows with Missing Values: (435, 17)\n"
     ]
    }
   ],
   "source": [
    "#Dropping missing data\n",
    "\n",
    "# Convert '?' to NaN\n",
    "df[df == \"?\"] = np.nan\n",
    "\n",
    "# Print the number of NaNs\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Print shape of original DataFrame\n",
    "print(\"Shape of Original DataFrame: {}\".format(df.shape))\n",
    "\n",
    "# Print shape of new DataFrame\n",
    "print(\"Shape of DataFrame After Dropping All Rows with Missing Values: {}\".format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create arrays for the features and the response variable\n",
    "y = df[\"party\"].values\n",
    "X = df.drop(\"party\", axis=1).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n\n    democrat       0.99      0.96      0.98        85\n  republican       0.94      0.98      0.96        46\n\n   micro avg       0.97      0.97      0.97       131\n   macro avg       0.96      0.97      0.97       131\nweighted avg       0.97      0.97      0.97       131\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LE HOANG NHAN\\PycharmProjects\\merging-dataframes -- Olympic data\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n  warnings.warn(msg, category=DeprecationWarning)\nC:\\Users\\LE HOANG NHAN\\PycharmProjects\\merging-dataframes -- Olympic data\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n  warnings.warn(msg, category=DeprecationWarning)\nC:\\Users\\LE HOANG NHAN\\PycharmProjects\\merging-dataframes -- Olympic data\\venv\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Imputing missing data in a ML Pipeline\n",
    "\n",
    "# Import the Imputer module\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Setup the Imputation transformer: imp\n",
    "imp = Imputer(missing_values='NaN', strategy='most_frequent', axis=0)\n",
    "\n",
    "# Instantiate the SVC classifier: clf\n",
    "clf = SVC()\n",
    "\n",
    "# Setup the pipeline with the required steps: steps\n",
    "steps = [('imputation', imp),\n",
    "        ('SVM', clf)]\n",
    "\n",
    "# Setup the pipeline steps: steps\n",
    "steps = [('imputation', Imputer(missing_values='NaN', strategy='most_frequent', axis=0)),\n",
    "        ('SVM', SVC())]\n",
    "\n",
    "# Create the pipeline: pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit the pipeline to the train set\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Compute metrics\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n0            7.0              0.27         0.36            20.7      0.045   \n1            6.3              0.30         0.34             1.6      0.049   \n2            8.1              0.28         0.40             6.9      0.050   \n3            7.2              0.23         0.32             8.5      0.058   \n4            7.2              0.23         0.32             8.5      0.058   \n\n   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n0                 45.0                 170.0   1.0010  3.00       0.45   \n1                 14.0                 132.0   0.9940  3.30       0.49   \n2                 30.0                  97.0   0.9951  3.26       0.44   \n3                 47.0                 186.0   0.9956  3.19       0.40   \n4                 47.0                 186.0   0.9956  3.19       0.40   \n\n   alcohol  quality  \n0      8.8        6  \n1      9.5        6  \n2     10.1        6  \n3      9.9        6  \n4      9.9        6  \n"
     ]
    }
   ],
   "source": [
    "# Read in the data file: df\n",
    "df = pd.read_csv('white-wine.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create arrays for the features and the response variable\n",
    "y = (df[\"quality\"].values)<5\n",
    "\n",
    "X = df.drop(\"quality\", axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Unscaled Features: 18.432687072460002\nStandard Deviation of Unscaled Features: 41.54494764094571\nMean of Scaled Features: 2.7314972981668206e-15\nStandard Deviation of Scaled Features: 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "#Centering and scaling your data\n",
    "\n",
    "# Scale the features: X_scaled\n",
    "X_scaled = scale(X)\n",
    "\n",
    "# Print the mean and standard deviation of the unscaled features\n",
    "print(\"Mean of Unscaled Features: {}\".format(np.mean(X))) \n",
    "print(\"Standard Deviation of Unscaled Features: {}\".format(np.std(X)))\n",
    "\n",
    "# Print the mean and standard deviation of the scaled features\n",
    "print(\"Mean of Scaled Features: {}\".format(np.mean(X_scaled))) \n",
    "print(\"Standard Deviation of Scaled Features: {}\".format(np.std(X_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Scaling: 0.964625850340136\nAccuracy without Scaling: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "#Centering and scaling in a pipeline\n",
    "\n",
    "# Import the necessary modules\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Setup the pipeline steps: steps\n",
    "steps = [('scaler', StandardScaler()),\n",
    "        ('knn', KNeighborsClassifier())]\n",
    "        \n",
    "# Create the pipeline: pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit the pipeline to the training set: knn_scaled\n",
    "knn_scaled = pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Instantiate and fit a k-NN classifier to the unscaled data\n",
    "knn_unscaled = KNeighborsClassifier().fit(X_train, y_train)\n",
    "\n",
    "# Compute and print metrics\n",
    "print('Accuracy with Scaling: {}'.format(knn_scaled.score(X_test,y_test)))\n",
    "print('Accuracy without Scaling: {}'.format(knn_unscaled.score(X_test,y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LE HOANG NHAN\\PycharmProjects\\merging-dataframes -- Olympic data\\venv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9693877551020408\n              precision    recall  f1-score   support\n\n       False       0.97      1.00      0.98       951\n        True       0.43      0.10      0.17        29\n\n   micro avg       0.97      0.97      0.97       980\n   macro avg       0.70      0.55      0.58       980\nweighted avg       0.96      0.97      0.96       980\n\nTuned Model Parameters: {'SVM__C': 100, 'SVM__gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "#Pipeline for classification: SVM classifier \n",
    "\n",
    "# Import necessary modules\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Setup the pipeline\n",
    "steps = [('scaler', StandardScaler()),\n",
    "         ('SVM', SVC())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Specify the hyperparameter space\n",
    "parameters = {'SVM__C':[1, 10, 100],\n",
    "              'SVM__gamma':[0.1, 0.01]}\n",
    "\n",
    "# Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=21)\n",
    "\n",
    "# Instantiate the GridSearchCV object: cv\n",
    "cv = GridSearchCV(pipeline,parameters)\n",
    "\n",
    "# Fit to the training set\n",
    "cv.fit(X_train,y_train)\n",
    "\n",
    "# Predict the labels of the test set: y_pred\n",
    "y_pred = cv.predict(X_test)\n",
    "\n",
    "# Compute and print metrics\n",
    "print(\"Accuracy: {}\".format(cv.score(X_test, y_test)))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Tuned Model Parameters: {}\".format(cv.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
